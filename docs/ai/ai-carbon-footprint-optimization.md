# üí® HUELLA DE CARBONO IA (GREEN AI)

**Versi√≥n:** 1.0
**Squad:** 306 Greta-1
**Problema:** Una consulta a GPT-4 consume 25x m√°s energ√≠a que una b√∫squeda en Google. Si 100.000 vecinos preguntan tonteras a la IA, calentamos el planeta.

---

## üéØ Inteligencia, no Desperdicio
Usar LLMs gigantes para tareas triviales es irresponsable ambientalmente.

## üõ°Ô∏è ESTRATEGIA DE "ECO-MODELS"

### 1. Modelo Correcto para la Tarea Correcta (Routing)
*   **Tier 1 (Bajo Carbono):** Regex / NLP Cl√°sico. Para validaciones simples (ej: "¬øEst√° insultando?"). Costo energ√©tico: ~0.
*   **Tier 2 (Medio Carbono):** Modelo Destilado (ej: 3B params cuantizado) corriendo en CPU local o Edge. Para autocompletado y clasificaci√≥n.
*   **Tier 3 (Alto Carbono):** LLM Fundacional (ej: GPT-4). Solo se invoca para razonamiento complejo ("Resume esta ley").

### 2. Caching Sem√°ntico Agresivo
*   Si el vecino A pregunta "¬øC√≥mo saco hora de c√©dula?" y el vecino B pregunta lo mismo 10 segundos despu√©s:
    *   No llamamos a la IA dos veces.
    *   Respondemos desde cache vectorial (Redis VSS).
    *   **Meta:** 40% de "Cache Hit Ratio" en consultas ciudadanas.

### 3. Presupuesto de Tokens de CO2
*   Monitor de emisiones en tiempo real (API Carbon Aware SDK).
*   Si la intensidad de carbono de la red el√©ctrica de la regi√≥n de inferencia es alta (hora punta carb√≥n), posponer tareas batch no urgentes de IA para la noche (cuando hay viento/agua).

---
*No quememos carb√≥n para generar tokens.*
