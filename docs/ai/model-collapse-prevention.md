# ðŸ“‰ IA SALUDABLE: PREVENCIÃ“N DE MODEL COLLAPSE

**VersiÃ³n:** 1.0  
**Ãšltima actualizaciÃ³n:** 19 Febrero 2026  
**EscuadrÃ³n:** 122 â€” Data-Sci-2: Model Collapse  
**Soluciona:** Hallazgo DS2-01 (DegradaciÃ³n por Auto-Entrenamiento)

---

## ðŸŽ¯ El Problema de Datos
OpenClaw (nuestra IA) genera resÃºmenes. Luego usamos esos resÃºmenes para re-entrenar la v2.
Resultado: La IA empieza a olvidar la realidad y amplifica sus propias alucinaciones ("Inbreeding" digital). La calidad colapsa.

---

## ðŸ§¬ Estrategia de Higiene de Datos

### 1. Watermarking de Datos SintÃ©ticos
*   Todo texto generado por Civia/OpenClaw se guarda en la DB con metadata `is_synthetic = true`.
*   **Regla de Oro:** El set de entrenamiento NUNCA debe contener datos con `is_synthetic = true`.

### 2. InyecciÃ³n de Realidad (Fresh Data)
*   Para cada ciclo de Fine-Tuning, se debe inyectar un 20% de "Datos Frescos Humanos" (leyes nuevas, noticias verificadas, papers acadÃ©micos).
*   Si no hay suficientes datos humanos nuevos, **NO SE RE-ENTRENA**. Mejor un modelo viejo estable que uno nuevo demente.

### 3. MÃ©tricas de Perplejidad (Perplexity Monitoring)
*   Evaluar el modelo contra un set de validaciÃ³n humano *fijo*.
*   Si la perplejidad sube (o la diversidad de vocabulario baja), es sÃ­ntoma de colapso. Rollback inmediato al checkpoint anterior.

---

## ðŸ§ª Test del "Eco"
1.  Entrenar un modelo pequeÃ±o solo con outputs del modelo anterior por 5 generaciones.
2.  Evaluar calidad.
3.  **Ã‰xito:** Demostrar que la calidad se degrada, validando la necesidad del filtro `is_synthetic`.

---
*Documento generado para cerrar Hallazgo DS2-01.*
