# üñºÔ∏è EL MEME OFENSIVO (VISI√ìN POR COMPUTADOR)

**Versi√≥n:** 1.0
**Squad:** 341 Dawkins-1
**Problema:** Los filtros de texto no detectan una foto de un pr√≥cer nacional con s√≠mbolos de odio superpuestos. Los memes son el vector principal de radicalizaci√≥n.

---

## üéØ Si una imagen vale mil palabras, necesitamos leerlas todas
La moderaci√≥n debe poder "ver".

## üõ°Ô∏è PROTOCOLO DE AN√ÅLISIS VISUAL

### 1. OCR + Contexto (Meme-Text)
*   Extraemos el texto dentro de la imagen.
*   No basta con leerlo. *"¬°Qu√© linda chimenea!"* sobre una foto de un incendio es odio, no arquitectura.
*   Analizamos la **Disonancia Texto-Imagen**.

### 2. Detecci√≥n de Simbolog√≠a de Odio (Hate Symbol Database)
*   Base de datos visual de s√≠mbolos de odio locales (ej: parches de grupos extremistas, caricaturas deshumanizantes).
*   Fine-tuning del modelo de visi√≥n para reconocer variantes locales (no solo sv√°sticas, sino s√≠mbolos espec√≠ficos de la historia de Chile).

### 3. Hashing Perceptual (PDQ Hash)
*   Si un meme es marcado como ilegal (pornograf√≠a infantil, incitaci√≥n a violencia), calculamos su **Hash Perceptual**.
*   Los filtros bloquean autom√°ticamente cualquier re-subida de esa imagen, incluso si le cambian un poco el color o la recortan. Evita el "Whack-a-Mole".

---
*El odio no se puede esconder en un JPG.*
