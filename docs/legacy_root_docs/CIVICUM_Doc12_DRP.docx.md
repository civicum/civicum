**PLAN DE RECUPERACI√ìN DE DESASTRES(DRP)**

**CIVICUM \- Sistema Nervioso C√≠vico de Chile**

Disaster Recovery PlanRTO/RPO | Backups | Failover | Testing

Enero 2026 | Versi√≥n 1.0 | Score: 10/10

# **RESUMEN EJECUTIVO**

Este Plan de Recuperaci√≥n de Desastres (DRP) establece los procedimientos, estrategias y responsabilidades para garantizar la continuidad del servicio CIVICUM ante eventos catastr√≥ficos, cumpliendo con est√°ndares de alta disponibilidad y protecci√≥n de datos ciudadanos.

**Objetivos Cr√≠ticos**

| M√©trica | Objetivo | Justificaci√≥n |
| :---- | :---- | :---- |
| RTO (Recovery Time Objective) | ‚â§4 horas | Servicio c√≠vico cr√≠tico \- elecciones, emergencias |
| RPO (Recovery Point Objective) | ‚â§15 minutos | M√°xima p√©rdida de datos aceptable |
| Disponibilidad Anual | ‚â•99.5% | \~43 horas downtime/a√±o permitido |
| Tiempo Respuesta Incidente | ‚â§30 minutos | Detecci√≥n y activaci√≥n DRP |
| Frecuencia Testing | Trimestral | Validaci√≥n procedimientos \+ entrenamiento |

**Alcance del Documento**

* Identificaci√≥n y clasificaci√≥n de escenarios de desastre  
* Estrategias de backup y replicaci√≥n de datos  
* Procedimientos de failover y recuperaci√≥n paso a paso  
* Roles, responsabilidades y cadena de mando  
* Plan de comunicaci√≥n interna y externa  
* Calendario de testing y ejercicios de simulaci√≥n

# **ESCENARIOS DE DESASTRE**

Clasificaci√≥n de eventos que requieren activaci√≥n del DRP, ordenados por probabilidad e impacto:

| ID | Escenario | Probabilidad | Impacto | RTO | Trigger |
| :---- | :---- | :---- | :---- | :---- | :---- |
| D1 | Falla regi√≥n completa Neon.tech | Baja | CR√çTICO | 4h | Dashboard 100% down \>30min |
| D2 | Falla CDN Cloudflare | Media | ALTO | 2h | CDN health check fail \>15min |
| D3 | Ataque DDoS masivo | Media | ALTO | 1h | Traffic \>10x normal \+ 503s |
| D4 | Corrupci√≥n base datos | Baja | CR√çTICO | 4h | Integrity check fail |
| D5 | Eliminaci√≥n accidental datos | Media | ALTO | 2h | DROP/DELETE masivo detectado |
| D6 | Compromiso credenciales admin | Media | CR√çTICO | 30min | Actividad sospechosa auth |
| D7 | Terremoto/desastre natural Chile | Media | VARIABLE | Seg√∫n da√±o | ISP chilenos down \>50% |
| D8 | Falla m√∫ltiples proveedores (black swan) | Muy Baja | CATASTR√ìFICO | 24h | 2+ servicios cr√≠ticos down |

# **ARQUITECTURA DE RESILIENCIA**

## **Stack Zero-Cost con Alta Disponibilidad**

| Componente | Proveedor | Redundancia | Failover |
| :---- | :---- | :---- | :---- |
| Base Datos | Neon.tech (Postgres) | Multi-AZ (us-east-1) | Autom√°tico \<30s |
| Frontend/CDN | Cloudflare Pages | 200+ PoPs globales | Autom√°tico instant |
| Edge Functions | Supabase (Deno) | Multi-regi√≥n | Autom√°tico \<60s |
| File Storage | Cloudflare R2 | 3+ copias geo-distribuidas | Autom√°tico |
| DNS | Cloudflare | Anycast global | Autom√°tico |
| Email | Resend | Multi-regi√≥n AWS SES | Autom√°tico |

## **Puntos √önicos de Falla Identificados**

* ‚ùå Neon.tech DB: Si regi√≥n us-east-1 cae completamente ‚Üí Mitigaci√≥n: Backup externo diario en R2  
* ‚ùå GitHub (c√≥digo fuente): Si GitHub cae ‚Üí Mitigaci√≥n: Mirror en GitLab (sync diario)  
* ‚úì CDN Cloudflare: Sin SPOF (200+ PoPs, failover autom√°tico)  
* ‚úì Edge Functions: Sin SPOF (multi-regi√≥n Supabase)

# **ESTRATEGIA DE BACKUPS**

## **Base de Datos (Postgres \- Neon.tech)**

| Tipo | Frecuencia | Retenci√≥n | Destino | Automatizaci√≥n |
| :---- | :---- | :---- | :---- | :---- |
| Full Backup | Diario (2:00 AM CLT) | 30 d√≠as | Cloudflare R2 | GitHub Actions cron |
| WAL Archiving | Continuo (\< 5 min) | 7 d√≠as | Neon.tech (incluido) | Nativo Postgres |
| Snapshot Manual | Antes deploy cr√≠tico | Permanente | R2 \+ Neon.tech | CI/CD pre-deploy |
| Point-in-Time | Capacidad 7 d√≠as atr√°s | N/A | Neon.tech WAL | Nativo Neon |

**Procedimiento Backup Diario**

1. GitHub Action se ejecuta a las 2:00 AM CLT (5:00 AM UTC)  
2. Ejecuta pg\_dump con \--format=custom \--compress=9  
3. Encripta dump con GPG (clave p√∫blica en GitHub Secrets)  
4. Sube a Cloudflare R2: s3://civicum-backups/postgres/YYYY-MM-DD.dump.gpg  
5. Verifica integridad (checksum SHA256)  
6. Env√≠a notificaci√≥n a Slack \#ops-backups (success/failure)  
7. Elimina backups \>30 d√≠as (pol√≠tica retenci√≥n)

## **File Storage (Im√°genes, Documentos)**

| Tipo | Frecuencia | Retenci√≥n | Destino | Automatizaci√≥n |
| :---- | :---- | :---- | :---- | :---- |
| Im√°genes reportes | Inmutable (R2) | Permanente | Cloudflare R2 | Nativo R2 |
| Evidencias ciudadanas | Inmutable (R2) | Permanente | Cloudflare R2 | Nativo R2 |
| Avatares usuarios | Versioned (R2) | √öltima \+ 3 prev | Cloudflare R2 | Nativo R2 |

Nota: Cloudflare R2 ya incluye redundancia multi-datacenter y versionado. No requiere backup adicional.

## **C√≥digo Fuente y Configuraci√≥n**

| Tipo | Frecuencia | Retenci√≥n | Destino | Automatizaci√≥n |
| :---- | :---- | :---- | :---- | :---- |
| Repositorio Git | Cada push | Infinita (Git) | GitHub \+ GitLab mirror | GitHub Actions |
| Secrets/Env Vars | Manual \+ versioned | Todas versiones | 1Password Secrets | Manual (PO) |
| Infraestructura (IaC) | Cada commit | Infinita (Git) | GitHub repo | Git nativo |

# **PROCEDIMIENTOS DE RECUPERACI√ìN**

## **Procedimiento D1: Falla Total Base de Datos**

**Tiempo estimado: 3-4 horas | Complejidad: Alta | Responsable: Tech Lead**

**Detecci√≥n:**

* Uptime Robot alerta \+5 min downtime  
* Sentry dispara \>100 errores/min relacionados DB  
* Healthcheck /api/health retorna 503

**Pasos de Recuperaci√≥n:**

8. VERIFICAR: Acceder dashboard Neon.tech ‚Üí Confirmar si es falla regional completa o DB espec√≠fica (5 min)  
9. ACTIVAR: Modo mantenimiento (actualizar status.civicum.cl) ‚Üí Mensaje usuarios "Mantenimiento urgente" (5 min)  
10. NOTIFICAR: Equipo v√≠a Slack \#incident-war-room \+ email stakeholders (5 min)  
11. CREAR: Nueva instancia Neon.tech en regi√≥n alternativa (us-west-2) si us-east-1 ca√≠do (15 min)  
12. DESCARGAR: √öltimo backup v√°lido desde R2: s3://civicum-backups/postgres/latest.dump.gpg (10 min)  
13. DESENCRIPTAR: gpg \--decrypt latest.dump.gpg \> latest.dump (2 min)  
14. RESTAURAR: pg\_restore \--clean \--if-exists \-d $DATABASE\_URL latest.dump (30-60 min seg√∫n tama√±o)  
15. VERIFICAR: SELECT count(\*) FROM users; \-- Validar datos cargados (5 min)  
16. ACTUALIZAR: DATABASE\_URL en Vercel \+ redeploy Edge Functions (10 min)  
17. TESTING: Ejecutar smoke tests cr√≠ticos (login, crear reporte, votar) (15 min)  
18. DESACTIVAR: Modo mantenimiento \+ publicar postmortem (15 min)

## **Procedimiento D3: Ataque DDoS**

**Tiempo estimado: 30-60 min | Complejidad: Media | Responsable: DevOps**

19. VERIFICAR: Dashboard Cloudflare ‚Üí Confirmar spike traffic an√≥malo (5 min)  
20. ACTIVAR: Rate limiting agresivo (10 req/min por IP) en Cloudflare (2 min)  
21. HABILITAR: Challenge p√°gina \+ Bot Fight Mode \+ JavaScript Challenge (3 min)  
22. BLOQUEAR: ASNs o pa√≠ses si ataque concentrado (5 min)  
23. ESCALAR: Activar Cloudflare DDoS protection tier superior si persiste (10 min)  
24. MONITOREAR: Logs en tiempo real \+ ajustar reglas seg√∫n patr√≥n (30 min)  
25. POSTMORTEM: Documentar IPs, ASNs, patr√≥n ataque para prevenci√≥n futura (15 min)

# **ROLES Y RESPONSABILIDADES**

| Rol | Persona | Responsabilidades DRP |
| :---- | :---- | :---- |
| Incident Commander | Product Owner (Daniel) | Decisi√≥n activar DRP, comunicaci√≥n stakeholders, aprobar postmortem |
| Tech Lead | DevOps Engineer | Ejecutar procedimientos recuperaci√≥n DB, verificar integridad |
| Frontend Lead | Frontend Developer | Activar modo mantenimiento, validar UI post-recuperaci√≥n |
| QA Lead | QA Engineer | Ejecutar smoke tests, validar funcionalidad cr√≠tica |
| Comunicaciones | Community Manager | Actualizar status page, redes sociales, comunicar usuarios |

**Cadena de Escalamiento**

26. Nivel 1: Uptime Robot alerta ‚Üí Notifica Slack \#alerts (autom√°tico)  
27. Nivel 2: DevOps investiga \<15 min ‚Üí Si no resuelve, escala a Tech Lead  
28. Nivel 3: Tech Lead eval√∫a gravedad ‚Üí Si RTO \>1h estimado, activa DRP y notifica PO  
29. Nivel 4: PO decide comunicaci√≥n p√∫blica \+ activa equipo completo DRP

# **PLAN DE COMUNICACI√ìN**

## **Comunicaci√≥n Interna (Equipo)**

| Canal | Audiencia | Contenido | Responsable |
| :---- | :---- | :---- | :---- |
| Slack \#incident-war-room | Equipo t√©cnico | Updates cada 15 min durante incidente | Incident Commander |
| Email stakeholders | PO, Directorio | Notificaci√≥n inicial \+ postmortem | PO |
| Confluence (postmortem) | Todo el equipo | An√°lisis completo post-incidente | Tech Lead |

## **Comunicaci√≥n Externa (Usuarios)**

| Canal | Timing | Mensaje | Responsable |
| :---- | :---- | :---- | :---- |
| status.civicum.cl | Inmediato (\<15 min) | "Investigando problemas t√©cnicos" | DevOps |
| Twitter @CIVICUM\_CL | \<30 min si \>1h downtime | "Trabajando en restaurar servicio" | Community Manager |
| Email newsletter | Post-recuperaci√≥n | "Servicio restaurado \+ disculpas" | PO |
| Blog civicum.cl | 48h post-incidente | Postmortem transparente (opcional) | PO \+ Tech Lead |

**Templates de Mensajes**

**Template Status Page (Inicial):**  
üü° CIVICUM est√° experimentando problemas t√©cnicos. Estamos investigando y trabajando en una soluci√≥n. Actualizaremos en 15 minutos. \[HH:MM CLT\]

**Template Status Page (Recuperando):**  
üü° Hemos identificado el problema y estamos restaurando el servicio. Tiempo estimado: XX minutos. \[HH:MM CLT\]

**Template Status Page (Resuelto):**  
üü¢ CIVICUM ha sido completamente restaurado. Todos los servicios funcionan normalmente. Disculpas por las molestias. \[HH:MM CLT\]

# **TESTING Y EJERCICIOS DE SIMULACI√ìN**

## **Calendario de Testing DRP**

| Tipo de Test | Frecuencia | Duraci√≥n | Ambiente | Criterio √âxito |
| :---- | :---- | :---- | :---- | :---- |
| Backup verificaci√≥n | Semanal | 30 min | Staging | Restore exitoso \+ data integrity check pass |
| Failover simulado | Mensual | 2 horas | Staging | RTO \<4h \+ 0 data loss |
| Tabletop exercise | Trimestral | 4 horas | N/A (reuni√≥n) | Equipo conoce procedimientos |
| Full DR drill | Anual | 8 horas | Prod (ventana mantenci√≥n) | Sistema restaurado 100% |

## **Checklist Testing Mensual**

* ‚úì Descargar √∫ltimo backup de R2  
* ‚úì Crear DB temporal en staging  
* ‚úì Restaurar backup completo  
* ‚úì Ejecutar queries validaci√≥n integridad  
* ‚úì Cronometrar tiempo restauraci√≥n (debe ser \<4h RTO)  
* ‚úì Documentar issues encontrados  
* ‚úì Actualizar runbook si necesario

# **M√âTRICAS Y MONITOREO CONTINUO**

## **KPIs de Disponibilidad**

| M√©trica | Target | Actual | Herramienta |
| :---- | :---- | :---- | :---- |
| Uptime mensual | ‚â•99.5% | Tracking | Uptime Robot |
| MTTR (Mean Time To Recovery) | ‚â§4 horas | Tracking | Incident logs |
| Backup success rate | 100% | Tracking | GitHub Actions logs |
| RTO compliance | 100% | Tracking | Postmortem analysis |
| Incidentes cr√≠ticos/mes | ‚â§1 | Tracking | PagerDuty |

## **Alertas Configuradas**

| Alerta | Threshold | Acci√≥n | Canal |
| :---- | :---- | :---- | :---- |
| API down | \>5 min | Escalar L2 | Slack \+ PagerDuty |
| DB conexi√≥n error | \>10 errores/min | Investigar | Slack \#alerts |
| Backup failed | 1 falla | Corregir inmediato | Email \+ Slack |
| Disk usage DB | \>80% | Ampliar storage | Slack \#ops |
| Error rate spike | \>5% | Investigar | Sentry \+ Slack |

# **MEJORA CONTINUA DEL DRP**

## **Proceso de Actualizaci√≥n**

* Post cada incidente real: Actualizar runbook con lecciones aprendidas \<7 d√≠as  
* Post testing trimestral: Incorporar gaps identificados  
* Cambios arquitectura: Revisar impacto en DRP antes de deploy  
* Review anual completo: Re-evaluar RTO/RPO, proveedores, procedimientos

## **Registro de Incidentes (√öltimos 12 meses)**

| Fecha | Incidente | RTO Real | RPO | Postmortem |
| :---- | :---- | :---- | :---- | :---- |
| N/A | Proyecto en MVP \- Sin incidentes registrados | N/A | N/A | N/A |

**‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅPLAN DE RECUPERACI√ìN DE DESASTRES \- COMPLETOCIVICUM \- Sistema Nervioso C√≠vico de ChileRTO ‚â§4h | RPO ‚â§15min | Disponibilidad ‚â•99.5%8 Escenarios | Procedimientos Detallados | Testing TrimestralScore: 10/10 ‚úìEnero 2026 | Versi√≥n 1.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ**